{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authtoken = 'CYmZJQTZk9cM-5LUZxD_'\n",
    "def get_data_quandl(symbol, start_date, end_date):\n",
    "    data = quandl.get(symbol, start_date=start_date, \n",
    "                      end_date=end_date, authtoken=authtoken)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    \"\"\"Generate features for a stock/index based on historical price and performance\n",
    "    Args:\n",
    "        df(dataframe with columns \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\")\n",
    "    Returns:\n",
    "        dataframe, data set with new features\n",
    "        \"\"\"\n",
    "    df_new = pd.DataFrame()\n",
    "    # 6 original features\n",
    "    df_new['open'] = df['Open']\n",
    "    df_new['open_1'] = df['Open'].shift(1)\n",
    "    # Shift index by 1, in order to take the value of previous day. For example, [1, 3, 4, 2] -> [N/A, 1, 3, 4]\n",
    "    df_new['close_1'] = df['Close'].shift(1)\n",
    "    df_new['high_1'] = df['High'].shift(1)\n",
    "    df_new['low_1'] = df['Low'].shift(1)\n",
    "    df_new['volume_1'] = df['Volume'].shift(1)\n",
    "    # 31 original features\n",
    "    # average price\n",
    "    df_new['avg_price_5'] = df['Close'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_price_30'] = df['Close'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_price_365'] = df['Close'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n",
    "    # average volume\n",
    "    df_new['avg_volume_5'] = df['Volume'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_volume_30'] = df['Volume'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_volume_365'] = df['Volume'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n",
    "    # standard deviation of prices\n",
    "    df_new['std_price_5'] = df['Close'].rolling(5).std().shift(1)\n",
    "    # rolling_mean calculates the moving standard deviation given a window\n",
    "    df_new['std_price_30'] = df['Close'].rolling(21).std().shift(1)\n",
    "    df_new['std_price_365'] = df['Close'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n",
    "    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n",
    "    # standard deviation of volumes\n",
    "    df_new['std_volume_5'] = df['Volume'].rolling(5).std().shift(1)\n",
    "    df_new['std_volume_30'] = df['Volume'].rolling(21).std().shift(1)\n",
    "    df_new['std_volume_365'] = df['Volume'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n",
    "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n",
    "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n",
    "    # return\n",
    "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)\n",
    "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n",
    "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n",
    "    df_new['moving_avg_5'] = df_new['return_1'].rolling(5).mean()\n",
    "    df_new['moving_avg_30'] = df_new['return_1'].rolling(21).mean()\n",
    "    df_new['moving_avg_365'] = df_new['return_1'].rolling(252).mean()\n",
    "    # the target\n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    # This will drop rows with any N/A value, which is by-product of moving average/std.\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quandl.get_table('SHARADAR/SEP', ticker=['AAPL','TSLA'])\n",
    "symbol = 'EOD/AAPL'\n",
    "start = '1988-01-01'\n",
    "end = '2015-12-31'\n",
    "data_raw = get_data_quandl(symbol, start, end)\n",
    "data = generate_features(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction(X, weights):\n",
    "    \"\"\" Compute the prediction y_hat based on current weights\n",
    "    Args:\n",
    "    X (numpy.ndarray) \n",
    "    weights (numpy.ndarray)\n",
    "    Returns:\n",
    "    numpy.ndarray, y_hat of X under weights \n",
    "    \"\"\"\n",
    "    predictions = np.dot(X, weights)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_gd(X_train, y_train, weights, learning_rate):\n",
    "    predictions = compute_prediction(X_train, weights)\n",
    "    weights_delta = np.dot(X_train.T, y_train - predictions)\n",
    "    m = y_train.shape[0]\n",
    "    weights += learning_rate / float(m) * weights_delta\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, weights):\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost = np.mean((predictions - y) ** 2 / 2.0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "        weights = np.zeros(X_train.shape[1])\n",
    "        for iteration in range(max_iter):\n",
    "            weights = update_weights_gd(X_train, y_train, weights, learning_rate)\n",
    "            if iteration % 100 == 0:\n",
    "                print(compute_cost(X_train, y_train, weights))\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.array([[6], [2], [3], [4], [1], \n",
    "                    [5], [2], [6], [4], [7]])\n",
    "y_train = np.array([5.5, 1.6, 2.2, 3.7, 0.8, \n",
    "                    5.2, 1.5, 5.3, 4.4, 6.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.571972628\n"
     ]
    }
   ],
   "source": [
    "weights = train_linear_regression(X_train, y_train, \n",
    "                                  max_iter=100, learning_rate=0.01, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "X_test = np.array([[1.3], [3.5], [5.2], [2.8]])\n",
    "predictions = predict(X_test, weights)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train[:, 0], y_train, marker='o', c='b')\n",
    "plt.scatter(X_test[:, 0], predictions, marker='*', c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "regressor = SGDRegressor(loss='squared_loss', penalty='l2', \n",
    "                         alpha=0.0001, learning_rate='constant', eta0=0.01, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99706088 3.23393923 4.96243613 2.52220521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "start_train = datetime.datetime(1988, 1, 1, 0, 0)\n",
    "end_train = datetime.datetime(2014, 12, 31, 0, 0)\n",
    "data_train = data.loc[start_train:end_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = list(data.drop(['close'], axis=1).columns)\n",
    "y_column = 'close'\n",
    "X_train = data_train[X_columns]\n",
    "y_train = data_train[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 37)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(83,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_test = datetime.datetime(2015, 1, 1, 0, 0)\n",
    "end_test = datetime.datetime(2015, 12, 31, 0, 0)\n",
    "data_test = data.loc[start_test:end_test]\n",
    "X_test = data_test[X_columns]\n",
    "y_test = data_test[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 37)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:152: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=1000, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [3e-06, 1e-05, 3e-05], 'eta0': [0.01, 0.03, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"alpha\": [3e-06, 1e-5, 3e-5],\n",
    "              \"eta0\": [0.01, 0.03, 0.1],\n",
    "             }\n",
    "lr = SGDRegressor(penalty='l2', n_iter=1000)\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, \n",
    "                           scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3e-06, 'eta0': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "lr_best = grid_search.best_estimator_\n",
    "predictions = lr_best.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 75294.415\n",
      "MAE: 193.108\n",
      "R^2: -1278.894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericchiyembekeza/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': [30, 50], 'min_samples_split': [3, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {\"max_depth\": [30, 50],\n",
    "              \"min_samples_split\": [3, 5, 10],\n",
    "             }\n",
    "rf = RandomForestRegressor(n_estimators=1000)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, \n",
    "                           scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 50, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "rf_best = grid_search.best_estimator_\n",
    "predictions = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 78.814\n",
      "MAE: 7.012\n",
      "R^2: -0.340\n"
     ]
    }
   ],
   "source": [
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "param_grid = {\"C\": [1000, 3000, 10000],\n",
    "              \"epsilon\": [0.00001, 0.00003, 0.0001],\n",
    "             }\n",
    "svr = SVR(kernel='linear')\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "svr_best = grid_search.best_estimator_\n",
    "predictions = svr_best.predict(X_scaled_test)\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
