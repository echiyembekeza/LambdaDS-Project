{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYS_RECID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QTR</th>\n",
       "      <th>FACLNBR</th>\n",
       "      <th>MCARE_NBR</th>\n",
       "      <th>TYPE_SERV</th>\n",
       "      <th>SERV_LOC</th>\n",
       "      <th>PRO_CODE</th>\n",
       "      <th>FAC_REGION</th>\n",
       "      <th>FAC_COUNTY</th>\n",
       "      <th>...</th>\n",
       "      <th>OBSERCHGS</th>\n",
       "      <th>GASTROCHGS</th>\n",
       "      <th>LITHOCHGS</th>\n",
       "      <th>OTHCHGS</th>\n",
       "      <th>TCHGS</th>\n",
       "      <th>PRINPROC</th>\n",
       "      <th>OTHPROC1</th>\n",
       "      <th>OTHPROC2</th>\n",
       "      <th>OTHPROC3</th>\n",
       "      <th>OTHPROC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100140850</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>100029</td>\n",
       "      <td>100029</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>2164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100140851</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>100029</td>\n",
       "      <td>100029</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100140852</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>100029</td>\n",
       "      <td>100029</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100140853</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>100029</td>\n",
       "      <td>100029</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>10413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100140854</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>100029</td>\n",
       "      <td>100029</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SYS_RECID  YEAR QTR FACLNBR MCARE_NBR TYPE_SERV SERV_LOC PRO_CODE  \\\n",
       "0  100140850  2018   1  100029    100029         2      NaN       23   \n",
       "1  100140851  2018   1  100029    100029         2      NaN       23   \n",
       "2  100140852  2018   1  100029    100029         2      NaN       23   \n",
       "3  100140853  2018   1  100029    100029         2      NaN       23   \n",
       "4  100140854  2018   1  100029    100029         2      NaN       23   \n",
       "\n",
       "  FAC_REGION FAC_COUNTY  ... OBSERCHGS GASTROCHGS LITHOCHGS OTHCHGS  TCHGS  \\\n",
       "0         11         13  ...         0          0         0     188   2164   \n",
       "1         11         13  ...         0          0         0       0  10816   \n",
       "2         11         13  ...         0          0         0       0   1596   \n",
       "3         11         13  ...         0          0         0     857  10413   \n",
       "4         11         13  ...         0          0         0       0   1849   \n",
       "\n",
       "  PRINPROC OTHPROC1 OTHPROC2 OTHPROC3 OTHPROC4  \n",
       "0      NaN      NaN      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "cols = ['SYS_RECID', 'YEAR', 'QTR', 'FACLNBR', 'MCARE_NBR', 'TYPE_SERV',\n",
    "       'SERV_LOC', 'PRO_CODE', 'FAC_REGION', 'FAC_COUNTY', 'ETHNICITY', 'RACE',\n",
    "       'SEX', 'AGE', 'LOSDAYS', 'WEEKDAY', 'ZIPCODE', 'PTCOUNTY', 'PTSTATE',\n",
    "       'PTCOUNTRY', 'ADMSRC', 'HR_ARRIVAL', 'EDHR_DISCH', 'PT_STATUS', 'PAYER',\n",
    "       'REASON_CDE', 'EVALCODE1', 'EVALCODE2', 'EVALCODE3', 'EVALCODE4',\n",
    "       'EVALCODE5', 'OTHCPT1', 'OTHCPT2', 'OTHCPT3', 'OTHCPT4', 'OTHCPT5',\n",
    "       'OTHCPT6', 'OTHCPT7', 'OTHCPT8', 'OTHCPT9', 'OTHCPT10', 'OTHCPT11',\n",
    "       'OTHCPT12', 'OTHCPT13', 'OTHCPT14', 'OTHCPT15', 'OTHCPT16', 'OTHCPT17',\n",
    "       'OTHCPT18', 'OTHCPT19', 'OTHCPT20', 'OTHCPT21', 'OTHCPT22', 'OTHCPT23',\n",
    "       'OTHCPT24', 'OTHCPT25', 'OTHCPT26', 'OTHCPT27', 'OTHCPT28', 'OTHCPT29',\n",
    "       'OTHCPT30', 'PRINDIAG', 'OTHDIAG1', 'OTHDIAG2', 'OTHDIAG3', 'OTHDIAG4',\n",
    "       'OTHDIAG5', 'OTHDIAG6', 'OTHDIAG7', 'OTHDIAG8', 'OTHDIAG9', 'ECMORB1',\n",
    "       'ECMORB2', 'ECMORB3', 'ATTEN_PHYI', 'ATTEN_PHYN', 'OPER_PHYID',\n",
    "       'OPER_PHYNP', 'OTHOPER_PH', 'OTHOPER__A', 'PHARMCHGS', 'MEDCHGS',\n",
    "       'LABCHGS', 'RADCHGS', 'CARDIOCHGS', 'OPRMCHGS', 'ANESCHGS', 'RECOVCHGS',\n",
    "       'ERCHGS', 'TRAUMACHGS', 'OBSERCHGS', 'GASTROCHGS', 'LITHOCHGS',\n",
    "       'OTHCHGS', 'TCHGS']\n",
    "\n",
    "unneeded_data = ['EVALCODE2','EVALCODE3','EVALCODE4','EVALCODE5','OTHCPT6','OTHCPT7','OTHCPT8',\n",
    "                'OTHCPT9','OTHCPT10','OTHCPT11','OTHCPT12','OTHCPT13', 'OTHCPT14',\n",
    "                'OTHCPT15', 'OTHCPT16', 'OTHCPT17', 'OTHCPT18','OTHCPT19', 'OTHCPT20',\n",
    "                'OTHCPT21', 'OTHCPT22', 'OTHCPT23', 'OTHCPT24','OTHCPT25', 'OTHCPT26',\n",
    "                'OTHCPT27', 'OTHCPT28', 'OTHCPT29', 'OTHCPT30','OTHDIAG6','OTHDIAG7',\n",
    "                'OTHDIAG8','OTHDIAG9','OTHOPER_PH','OTHOPER__A','PHARMCHGS', 'MEDCHGS', 'LABCHGS',\n",
    "                'RADCHGS', 'CARDIOCHGS', 'OPRMCHGS', 'ANESCHGS', 'RECOVCHGS', 'ERCHGS',\n",
    "                'TRAUMACHGS', 'OBSERCHGS', 'GASTROCHGS', 'LITHOCHGS', 'OTHCHGS','TCHGS','OPER_PHYID',\n",
    "                 'OPER_PHYNP','PRINPROC','OTHPROC1','OTHPROC2','OTHPROC3','OTHPROC4']\n",
    "\n",
    "df = pd.concat([pd.read_csv(f , dtype= object) for f in glob.glob('/Users/EricJC/Desktop/Data/*.csv')], ignore_index = True, sort=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the opioid codes that we are most interested in. We will filter the [REASON_CDE] column by these specific codes\n",
    "opioid_dx = ['F11.10','F11.120','F11.121',\n",
    "'F11.122','F11.129','F11.14','F11.150','F11.151','F11.159','F11.181','F11.182','F11.188',\n",
    "'F11.19','F11.20','F11.220','F11.221','F11.222','F11.229','F11.23','F11.24','F11.250',\n",
    "'F11.251','F11.259','F11.281','F11.282','F11.288','F11.29','F11.90','F11.920','F11.921',\n",
    "'F11.922','F11.929','F11.93','F11.94','F11.950','F11.951','F11.959','F11.981','F11.982',\n",
    "'F11.988','F11.99','T40.0X1A','T40.0X1D','T40.0X1S','T40.0X4A','T40.0X4D','T40.0X4S',\n",
    "'T40.0X5A','T40.0X5D','T40.0X5S','T40.1X1A','T40.1X1D','T40.1X1S','T40.1X4A','T40.1X4D',\n",
    "'T40.1X4S','T40.2X1A','T40.2X1D','T40.2X1S','T40.2X4A','T40.2X4D','T40.2X4S','T40.2X5A',\n",
    "'T40.2X5D','T40.2X5S','T40.3X1A','T40.3X1D','T40.3X1S','T40.3X4A','T40.3X4D','T40.3X4S',\n",
    "'T40.3X5A','T40.3X5D','T40.3X5S','T40.4X1A','T40.4X1D','T40.4X1S','T40.4X4A','T40.4X4D',\n",
    "'T40.4X4S','T40.4X5A','T40.4X5D','T40.4X5S','T40.601A','T40.601D','T40.601S','T40.604A',\n",
    "'T40.604D','T40.604S','T40.605A','T40.605D','T40.605S','T40.691A','T40.691D','T40.691S',\n",
    "'T40.694A','T40.694D','T40.694S','T40.695A','T40.695D','T40.695S','T40.0X2A','T40.0X2D',\n",
    "'T40.0X2S','T40.0X3A','T40.0X3D','T40.0X3S','T40.1X2A','T40.1X2D','T40.1X2S','T40.1X3A',\n",
    "'T40.1X3D','T40.1X3S','T40.2X2A','T40.2X2D','T40.2X2S','T40.2X3A','T40.2X3D','T40.2X3S',\n",
    "'T40.3X2A','T40.3X2D','T40.3X2S','T40.3X3A','T40.3X3D','T40.3X3S','T40.4X2A','T40.4X2D',\n",
    "'T40.4X2S','T40.4X3A','T40.4X3D','T40.4X3S','T40.602A','T40.602D','T40.602S','T40.603A',\n",
    "'T40.603D','T40.603S','T40.692A','T40.692D','T40.692S','T40.693A','T40.693D','T40.693S']\n",
    "def is_opioid_dx(opioid_dx):\n",
    "    if opioid_dx in ['F11.10','F11.120','F11.121',\n",
    "'F11.122','F11.129','F11.14','F11.150','F11.151','F11.159','F11.181','F11.182','F11.188',\n",
    "'F11.19','F11.20','F11.220','F11.221','F11.222','F11.229','F11.23','F11.24','F11.250',\n",
    "'F11.251','F11.259','F11.281','F11.282','F11.288','F11.29','F11.90','F11.920','F11.921',\n",
    "'F11.922','F11.929','F11.93','F11.94','F11.950','F11.951','F11.959','F11.981','F11.982',\n",
    "'F11.988','F11.99','T40.0X1A','T40.0X1D','T40.0X1S','T40.0X4A','T40.0X4D','T40.0X4S',\n",
    "'T40.0X5A','T40.0X5D','T40.0X5S','T40.1X1A','T40.1X1D','T40.1X1S','T40.1X4A','T40.1X4D',\n",
    "'T40.1X4S','T40.2X1A','T40.2X1D','T40.2X1S','T40.2X4A','T40.2X4D','T40.2X4S','T40.2X5A',\n",
    "'T40.2X5D','T40.2X5S','T40.3X1A','T40.3X1D','T40.3X1S','T40.3X4A','T40.3X4D','T40.3X4S',\n",
    "'T40.3X5A','T40.3X5D','T40.3X5S','T40.4X1A','T40.4X1D','T40.4X1S','T40.4X4A','T40.4X4D',\n",
    "'T40.4X4S','T40.4X5A','T40.4X5D','T40.4X5S','T40.601A','T40.601D','T40.601S','T40.604A',\n",
    "'T40.604D','T40.604S','T40.605A','T40.605D','T40.605S','T40.691A','T40.691D','T40.691S',\n",
    "'T40.694A','T40.694D','T40.694S','T40.695A','T40.695D','T40.695S','T40.0X2A','T40.0X2D',\n",
    "'T40.0X2S','T40.0X3A','T40.0X3D','T40.0X3S','T40.1X2A','T40.1X2D','T40.1X2S','T40.1X3A',\n",
    "'T40.1X3D','T40.1X3S','T40.2X2A','T40.2X2D','T40.2X2S','T40.2X3A','T40.2X3D','T40.2X3S',\n",
    "'T40.3X2A','T40.3X2D','T40.3X2S','T40.3X3A','T40.3X3D','T40.3X3S','T40.4X2A','T40.4X2D',\n",
    "'T40.4X2S','T40.4X3A','T40.4X3D','T40.4X3S','T40.602A','T40.602D','T40.602S','T40.603A',\n",
    "'T40.603D','T40.603S','T40.692A','T40.692D','T40.692S','T40.693A','T40.693D','T40.693S']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['REASON_CDE'] = df['REASON_CDE'].apply(is_opioid_dx)\n",
    "\n",
    "def is_night(arrtime):\n",
    "    arrtime_int = int(arrtime)\n",
    "    if ((arrtime_int >= 0) & (arrtime_int < 8)):\n",
    "        return 1\n",
    "    elif ((arrtime_int >= 20) & (arrtime_int < 23)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['HR_ARRIVAL'] = df['HR_ARRIVAL'].apply(is_night)\n",
    "df['AGE'] = df['AGE'].astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def roundup(x, n=10):\n",
    "    res = math.ceil(x/n)*n\n",
    "    if (x%n < n/2)and (x%n>0):\n",
    "        res-=n\n",
    "    return res\n",
    "\n",
    "num = df['AGE']\n",
    "df['AGE'] = [roundup(n) for n in num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filled the missing values with the value for \"unknown\"\n",
    "df['EVALCODE1'] = df['EVALCODE1'].fillna('99999')\n",
    "df['PTCOUNTRY'] = df['PTCOUNTRY'].fillna('99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['SYS_RECID','FACLNBR','MCARE_NBR','TYPE_SERV','SERV_LOC','PRO_CODE','EVALCODE2','EVALCODE3','EVALCODE4','EVALCODE5','OTHCPT6','OTHCPT7','OTHCPT8',\n",
    "             'OTHCPT9','OTHCPT10','OTHCPT11','OTHCPT12','OTHCPT13', 'OTHCPT14','OTHCPT15', 'OTHCPT16', 'OTHCPT17',\n",
    "             'OTHCPT18','OTHCPT19', 'OTHCPT20','OTHCPT21', 'OTHCPT22', 'OTHCPT23', 'OTHCPT24','OTHCPT25', 'OTHCPT26',\n",
    "             'OTHCPT27', 'OTHCPT28', 'OTHCPT29', 'OTHCPT30','OTHDIAG6','OTHDIAG7',\n",
    "             'OTHDIAG8','OTHDIAG9','OTHOPER_PH','OTHOPER__A','PHARMCHGS', 'MEDCHGS', 'LABCHGS',\n",
    "             'RADCHGS', 'CARDIOCHGS', 'OPRMCHGS', 'ANESCHGS', 'RECOVCHGS', 'ERCHGS',\n",
    "             'TRAUMACHGS', 'OBSERCHGS', 'GASTROCHGS', 'LITHOCHGS', 'OTHCHGS','TCHGS','OPER_PHYID',\n",
    "             'OPER_PHYNP','PRINPROC','OTHPROC1','OTHPROC2','OTHPROC3','OTHPROC4','OTHCPT1','OTHCPT2','OTHCPT3','OTHCPT4','OTHCPT5','PRINDIAG','OTHDIAG1','OTHDIAG2','OTHDIAG3','OTHDIAG4','OTHDIAG5','ECMORB1','ECMORB2','ECMORB3','ATTEN_PHYI','LOSDAYS','ZIPCODE','FAC_COUNTY','PTCOUNTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_target(data, target_name):\n",
    "       target = data[[target_name]]\n",
    "       data.drop(target_name, axis=1, inplace=True)\n",
    "       return (data, target)\n",
    "X, y = split_target(df, 'REASON_CDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after splitting my data into train and test with the code above, X contains the df and y contains the target (or response variable)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just to check...\n",
    "print(y_train.groupby('REASON_CDE').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break up the columns and only select the ones that I want to \"categorize\". I will need to do something with the ages\n",
    "#as well as the zip codes. Maybe I can stick to the regions for now.\n",
    "#I also need to drop the SYS_RECID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[:] = X_train.loc[:].apply(pd.to_numeric)\n",
    "X_test.loc[:] = X_test.loc[:].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cols = X_train.columns\n",
    "X_test_cols = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression model for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [LogisticRegression()]\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    coefs = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'coef': [clf.coef_[0,i] for i in range(len(X_train_cols))]\n",
    "       }\n",
    "    df_coefs = pd.DataFrame(coefs)\n",
    "    print(df_coefs.sort_values('coef', axis=0, ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs_rf = [RandomForestClassifier(n_estimators=100)]\n",
    "for clf in clfs_rf:\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    imps = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'imp': [clf.feature_importances_[i] for i in range(len(X_train_cols))]}\n",
    "    df_imps = pd.DataFrame(imps)\n",
    "    print(df_imps.sort_values('imp', axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_Tx = scaler.transform(X_train)\n",
    "X_test_Tx = scaler.transform(X_test)\n",
    "\n",
    "# Fit models that require scaling (e.g. neural networks)\n",
    "hl_sizes = [150,100,80,60,40,20]\n",
    "nn_clfs = [MLPClassifier(hidden_layer_sizes=(size,), random_state=42, verbose=True) for size in hl_sizes]\n",
    "for num, nn_clf in enumerate(nn_clfs):\n",
    "    print(str(hl_sizes[num]) + '-unit network:')\n",
    "    nn_clf.fit(X_train_Tx, y_train.ravel())\n",
    "    print('Training accuracy: ' + str(nn_clf.score(X_train_Tx, y_train)))\n",
    "    print('Validation accuracy: ' + str(nn_clf.score(X_test_Tx, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
