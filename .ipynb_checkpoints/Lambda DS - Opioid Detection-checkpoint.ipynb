{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.concat([pd.read_csv(f , usecols=['SYS_RECID','ZIPCODE','YEAR','QTR','FAC_REGION','ETHNICITY','RACE','SEX','AGE','WEEKDAY','PTSTATE','PTCOUNTRY','ADMSRC','HR_ARRIVAL','EDHR_DISCH','PT_STATUS','PAYER','REASON_CDE','ATTEN_PHYN'],\n",
    "                            dtype= \"category\") for f in glob.glob('/Users/EricJC/Documents/Data/*.csv')], ignore_index = True, sort=False)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the opioid codes that we are most interested in. We will filter the [REASON_CDE] column by these specific codes\n",
    "def is_opioid_dx(opioid_dx):\n",
    "    if opioid_dx in ['F11.10','F11.120','F11.121',\n",
    "'F11.122','F11.129','F11.14','F11.150','F11.151','F11.159','F11.181','F11.182','F11.188',\n",
    "'F11.19','F11.20','F11.220','F11.221','F11.222','F11.229','F11.23','F11.24','F11.250',\n",
    "'F11.251','F11.259','F11.281','F11.282','F11.288','F11.29','F11.90','F11.920','F11.921',\n",
    "'F11.922','F11.929','F11.93','F11.94','F11.950','F11.951','F11.959','F11.981','F11.982',\n",
    "'F11.988','F11.99','T40.0X1A','T40.0X1D','T40.0X1S','T40.0X4A','T40.0X4D','T40.0X4S',\n",
    "'T40.0X5A','T40.0X5D','T40.0X5S','T40.1X1A','T40.1X1D','T40.1X1S','T40.1X4A','T40.1X4D',\n",
    "'T40.1X4S','T40.2X1A','T40.2X1D','T40.2X1S','T40.2X4A','T40.2X4D','T40.2X4S','T40.2X5A',\n",
    "'T40.2X5D','T40.2X5S','T40.3X1A','T40.3X1D','T40.3X1S','T40.3X4A','T40.3X4D','T40.3X4S',\n",
    "'T40.3X5A','T40.3X5D','T40.3X5S','T40.4X1A','T40.4X1D','T40.4X1S','T40.4X4A','T40.4X4D',\n",
    "'T40.4X4S','T40.4X5A','T40.4X5D','T40.4X5S','T40.601A','T40.601D','T40.601S','T40.604A',\n",
    "'T40.604D','T40.604S','T40.605A','T40.605D','T40.605S','T40.691A','T40.691D','T40.691S',\n",
    "'T40.694A','T40.694D','T40.694S','T40.695A','T40.695D','T40.695S','T40.0X2A','T40.0X2D',\n",
    "'T40.0X2S','T40.0X3A','T40.0X3D','T40.0X3S','T40.1X2A','T40.1X2D','T40.1X2S','T40.1X3A',\n",
    "'T40.1X3D','T40.1X3S','T40.2X2A','T40.2X2D','T40.2X2S','T40.2X3A','T40.2X3D','T40.2X3S',\n",
    "'T40.3X2A','T40.3X2D','T40.3X2S','T40.3X3A','T40.3X3D','T40.3X3S','T40.4X2A','T40.4X2D',\n",
    "'T40.4X2S','T40.4X3A','T40.4X3D','T40.4X3S','T40.602A','T40.602D','T40.602S','T40.603A',\n",
    "'T40.603D','T40.603S','T40.692A','T40.692D','T40.692S','T40.693A','T40.693D','T40.693S']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['REASON_CDE_01'] = df['REASON_CDE'].apply(is_opioid_dx).astype('category')\n",
    "\n",
    "def is_night(arrtime):\n",
    "    arrtime_int = int(arrtime)\n",
    "    if ((arrtime_int >= 0) & (arrtime_int < 8)):\n",
    "        return 1\n",
    "    elif ((arrtime_int >= 20) & (arrtime_int < 23)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['HR_ARRIVAL_01'] = df['HR_ARRIVAL'].apply(is_night).astype('category')\n",
    "\n",
    "df['AGE'] = df['AGE'].astype(int)\n",
    "def roundup(x, n=10):\n",
    "    res = math.ceil(x/n)*n\n",
    "    if (x%n < n/2)and (x%n>0):\n",
    "        res-=n\n",
    "    return res\n",
    "\n",
    "num = df['AGE']\n",
    "df['AGES'] = [roundup(n) for n in num]\n",
    "df['AGES'] = df['AGES'].astype('category')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.select_dtypes(include=['category']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat['FAC_REGION'] = df_cat['FAC_REGION'].cat.codes\n",
    "df_cat['ETHNICITY'] = df_cat['ETHNICITY'].cat.codes\n",
    "df_cat['RACE'] = df_cat['RACE'].cat.codes\n",
    "df_cat['SEX'] = df_cat['SEX'].cat.codes\n",
    "df_cat['WEEKDAY'] = df_cat['WEEKDAY'].cat.codes\n",
    "df_cat['EDHR_DISCH'] = df_cat['EDHR_DISCH'].cat.codes\n",
    "df_cat['PT_STATUS'] = df_cat['PT_STATUS'].cat.codes\n",
    "df_cat['PAYER'] = df_cat['PAYER'].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cat_df_flights['carrier'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'carrier' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=df['WEEKDAY'], y=df['AGE'], hue=df['SEX'], kind=\"box\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots of Ages of Patients Grouped by Sex\n",
    "Below are 2 boxplots showing the distribution of ages of the patients presenting to the emergency departments grouped by sex. The data included values that would be considered outliers by this plot. Patients who are:   \n",
    "    Age 0 = 0 to 28 days  \n",
    "    Age 777 = 29 to 364 days (considered an outlier)  \n",
    "    Age 888 = 100 years and older (considered an outlier)  \n",
    "    Age 999 = Unknown (considered an outlier)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_boxplot = df.boxplot('AGE','SEX', rot=30, figsize=(5,6), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HR_ARRIVAL'] = df['HR_ARRIVAL'].astype(int)\n",
    "time_payer_boxplot = df.boxplot('HR_ARRIVAL','PAYER', rot=45, figsize=(9,6), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_admsrc_boxplot = df.boxplot('HR_ARRIVAL','ADMSRC', rot=45, figsize=(9,6), showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_race = df.groupby(['ETHNICITY', 'RACE']).size()\n",
    "eth_race.plot(kind='bar', width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WEEKDAY'] = df['WEEKDAY'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot\n",
    "#I need to create a df with just numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap((df['3','5','7','8','12','13']))\n",
    "plt.figure(figsize=(10,5)\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_race\n",
    "plt.bar(eth_race, eth_race_size, align='center', width=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filled the missing values with the value for \"unknown\"\n",
    "df['EVALCODE1'] = df['EVALCODE1'].fillna('99999')\n",
    "df['PTCOUNTRY'] = df['PTCOUNTRY'].fillna('99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_age = df['AGE'].unique()\n",
    "age_count =  df['AGE'].value_counts()\n",
    "\n",
    "plt.bar(x_age, age_count, align='center', width=5, alpha=1)\n",
    "plt.xticks(x_age)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Ages of ED Patients')\n",
    "plt.xlim(right=100, left=-5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_map = gpd.read_file('/Users/EricJC/Documents/Data/tl_2016_12_cousub.shp')\n",
    "fig.ax = plt.subplots(figsize = (15,15))\n",
    "florida_map.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "\n",
    "#output_file('vbar.html')\n",
    "\n",
    "p = figure(plot_width=400, plot_height=400)\n",
    "p.vbar(x=df['AGE'], width=0.5, bottom=0,\n",
    "       top=df['AGE'].count(), color=\"firebrick\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_target(data, target_name):\n",
    "       target = data[[target_name]]\n",
    "       data.drop(target_name, axis=1, inplace=True)\n",
    "       return (data, target)\n",
    "X, y = split_target(df, 'REASON_CDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after splitting my data into train and test with the code above, X contains the df and y contains the target (or response variable)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just to check...\n",
    "print(y_train.groupby('REASON_CDE').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[:] = X_train.loc[:].apply(pd.to_numeric)\n",
    "X_test.loc[:] = X_test.loc[:].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cols = X_train.columns\n",
    "X_test_cols = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df)\n",
    "print(integer_encoded)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression model for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [LogisticRegression()]\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    coefs = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'coef': [clf.coef_[0,i] for i in range(len(X_train_cols))]\n",
    "       }\n",
    "    df_coefs = pd.DataFrame(coefs)\n",
    "    print(df_coefs.sort_values('coef', axis=0, ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs_rf = [RandomForestClassifier(n_estimators=100)]\n",
    "for clf in clfs_rf:\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    print(type(clf))\n",
    "    print('Training accuracy: ' + str(clf.score(X_train, y_train)))\n",
    "    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))\n",
    "    imps = {\n",
    "        'column': [X_train_cols[i] for i in range(len(X_train_cols))],\n",
    "        'imp': [clf.feature_importances_[i] for i in range(len(X_train_cols))]}\n",
    "    df_imps = pd.DataFrame(imps)\n",
    "    print(df_imps.sort_values('imp', axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_Tx = scaler.transform(X_train)\n",
    "X_test_Tx = scaler.transform(X_test)\n",
    "\n",
    "# Fit models that require scaling (e.g. neural networks)\n",
    "hl_sizes = [150,100,80,60,40,20]\n",
    "nn_clfs = [MLPClassifier(hidden_layer_sizes=(size,), random_state=42, verbose=True) for size in hl_sizes]\n",
    "for num, nn_clf in enumerate(nn_clfs):\n",
    "    print(str(hl_sizes[num]) + '-unit network:')\n",
    "    nn_clf.fit(X_train_Tx, y_train.ravel())\n",
    "    print('Training accuracy: ' + str(nn_clf.score(X_train_Tx, y_train)))\n",
    "    print('Validation accuracy: ' + str(nn_clf.score(X_test_Tx, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importing the files originally as a whole, then changed the df multiple times by dropping columns.\n",
    "\n",
    "this proved to be quite slow, and used a lot of memory.\n",
    "\n",
    "So, i changed the way that the data was imported, just pulling the information that i was interested in\n",
    "\n",
    "I then created a few functions to help with cleaning my data.\n",
    "1. select the dx that i was interested in\n",
    "2. the second function looked at the time of a pt's arrival in the ED. I basically separated the times by \"late\" and \"not late\"\n",
    "since the data is representative of 24 hours in the day\n",
    "3. i decided to group the ages by decades\n",
    "\n",
    "the plots that will be shown will basically show a few things:\n",
    "    1. which zip codes have the highest number of pts for the dx codes of interest\n",
    "    2. what type of patients are frequenting the ED for the dx codes\n",
    "    3. what time of days and days of the week these visits are occuring\n",
    "    4. which physicians are showing higher utilization\n",
    "    these will be a mixture of heat maps and line graphs and bar charts\n",
    "    \n",
    "with the data structured in this fashion will provide a good foundation for machine learning models to be used for predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
